{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Load your data\n",
        "train_df = pd.read_csv('train_selected.csv')\n",
        "test_df = pd.read_csv('test_selected.csv')\n",
        "\n",
        "# Assuming 'emotions' contains multiple labels separated by commas\n",
        "train_df['emotions'] = train_df['emotions'].apply(lambda x: x.split(','))\n",
        "test_df['emotions'] = test_df['emotions'].apply(lambda x: x.split(','))\n",
        "\n",
        "# Step 4: Preprocess the Data\n",
        "# Encode the labels for multilabel classification\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train = mlb.fit_transform(train_df['emotions'])\n",
        "y_test = mlb.transform(test_df['emotions'])\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(train_df['text'])\n",
        "\n",
        "# Convert text to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_df['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n",
        "\n",
        "# Pad the sequences\n",
        "max_length = max(max(len(x) for x in train_sequences), max(len(x) for x in test_sequences))\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Step 5: Build the LSTM Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_length))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))  # No additional arguments\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(mlb.classes_), activation='sigmoid'))\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Step 6: Train the Model\n",
        "history = model.fit(train_padded, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Save the tokenizer and label binarizer\n",
        "import joblib\n",
        "with open('tokenizer.pkl', 'wb') as handle:\n",
        "    joblib.dump(tokenizer, handle)\n",
        "\n",
        "with open('mlb.pkl', 'wb') as handle:\n",
        "    joblib.dump(mlb, handle)\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "loss, accuracy = model.evaluate(test_padded, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysCAs7lmQrCx",
        "outputId": "349211df-68ed-4b2e-887d-70b8da52c016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "37/37 [==============================] - 30s 701ms/step - loss: 0.4649 - accuracy: 0.0367 - val_loss: 0.3158 - val_accuracy: 0.0078\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 26s 715ms/step - loss: 0.3467 - accuracy: 0.0500 - val_loss: 0.3090 - val_accuracy: 0.0078\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 25s 681ms/step - loss: 0.3391 - accuracy: 0.0518 - val_loss: 0.3088 - val_accuracy: 0.0078\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 23s 615ms/step - loss: 0.3313 - accuracy: 0.0518 - val_loss: 0.3089 - val_accuracy: 0.0078\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 23s 615ms/step - loss: 0.3269 - accuracy: 0.0617 - val_loss: 0.3086 - val_accuracy: 0.0078\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 25s 679ms/step - loss: 0.3252 - accuracy: 0.0470 - val_loss: 0.3080 - val_accuracy: 0.1047\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 25s 677ms/step - loss: 0.3220 - accuracy: 0.0492 - val_loss: 0.3079 - val_accuracy: 0.0078\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 24s 664ms/step - loss: 0.3208 - accuracy: 0.0535 - val_loss: 0.3078 - val_accuracy: 0.0078\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 24s 650ms/step - loss: 0.3202 - accuracy: 0.0522 - val_loss: 0.3079 - val_accuracy: 0.1047\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 24s 659ms/step - loss: 0.3194 - accuracy: 0.0518 - val_loss: 0.3078 - val_accuracy: 0.0078\n",
            "29/29 [==============================] - 3s 98ms/step - loss: 0.3061 - accuracy: 0.0166\n",
            "Test Accuracy: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t9CLlm4SIBy",
        "outputId": "7f2055a3-ff54-418d-a833-67ffa2979405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmePJjA0SLiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model.h5')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wWmu9WfASLNN",
        "outputId": "dab86fb5-fbe2-4732-fa77-80753cc28315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ccdbeb0d-eb95-42bd-a708-5abf3a131f94\", \"model.h5\", 9926808)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Example text input for prediction\n",
        "example_text = \"I can't do this anymore, I feel sad.\"\n",
        "\n",
        "# Load the model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# Load the tokenizer and label binarizer\n",
        "with open('tokenizer.pkl', 'rb') as handle:\n",
        "    tokenizer = joblib.load(handle)\n",
        "\n",
        "with open('mlb.pkl', 'rb') as handle:\n",
        "    mlb = joblib.load(handle)\n",
        "\n",
        "# Tokenize and pad the input text\n",
        "sequences = tokenizer.texts_to_sequences([example_text])\n",
        "padded_sequence = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(padded_sequence)\n",
        "\n",
        "# Adjust threshold\n",
        "threshold = 0.3\n",
        "predicted_labels = mlb.inverse_transform(predictions > threshold)\n",
        "\n",
        "# Clean the predicted labels\n",
        "cleaned_labels = [label.strip() for label in predicted_labels[0]]  # Clean up whitespace\n",
        "\n",
        "# Output the predictions\n",
        "print(f\"Predicted labels for the input '{example_text}': {cleaned_labels}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhCq4ROQIZ7j",
        "outputId": "95e96d9d-e713-4e25-a30c-ff7bcd261914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 724ms/step\n",
            "Predicted labels for the input 'I can't do this anymore, I feel sad.': [\"'hopelessness'\", \"'sadness'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58J3UcQglJ7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}